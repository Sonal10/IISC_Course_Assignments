{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid c1 is [0.65, 0.8, 0.2, 0.08]\n",
      "Centroid c2 is [0.89, 0.73, 0.68, 0.56]\n",
      "Centroid c3 is [0.73, 0.61, 0.74, 0.76]\n",
      "Initial Centroids are ([0.65, 0.8, 0.2, 0.08], [0.89, 0.73, 0.68, 0.56], [0.73, 0.61, 0.74, 0.76])\n",
      "Pass No.1\n",
      "([0.63, 0.78, 0.21, 0.1], [0.77, 0.64, 0.63, 0.53], [0.82, 0.66, 0.78, 0.79])\n",
      "Pass No.2\n",
      "([0.63, 0.78, 0.21, 0.1], [0.75, 0.62, 0.62, 0.53], [0.84, 0.69, 0.81, 0.82])\n",
      "Pass No.3\n",
      "([0.63, 0.78, 0.21, 0.1], [0.75, 0.62, 0.62, 0.53], [0.84, 0.69, 0.81, 0.82])\n",
      "Total no. of passes made are 3\n",
      "Out of while loop, final Centroids are: ([0.63, 0.78, 0.21, 0.1], [0.75, 0.62, 0.62, 0.53], [0.84, 0.69, 0.81, 0.82])\n"
     ]
    }
   ],
   "source": [
    "#Implementing k-means\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Read from file the data, put it into a dataframe in pandas\n",
    "\n",
    "training = pd.read_csv('train.csv',skipinitialspace=True,sep=\",\")\n",
    "#print(training.head())\n",
    "\n",
    "#test= pd.read_csv('test.csv',skipinitialspace=True,sep=\",\")\n",
    "#print(test.head())\n",
    "\n",
    "train_features = training.filter(['Norm_Sepal_Length','Norm_Sepal_Width','Norm_Petal_Length','Norm_Petal_Width'], axis=1)\n",
    "train_label = training.filter(['Class_Lab'],axis=1)\n",
    "train_label.columns=['Label']\n",
    "\n",
    "#test_features = test.filter(['Norm_Sepal_Length','Norm_Sepal_Width','Norm_Petal_Length','Norm_Petal_Width'], axis=1)\n",
    "#test_label = test.filter(['Class_Lab'],axis=1)\n",
    "#test_label.columns=['Label']\n",
    "\n",
    "#Choose initial seeds, initialise as centroids, initialise cluster buckets lists\n",
    "list1 = train_features.values.tolist()\n",
    "\n",
    "initial_c1 = list1[0]\n",
    "c1 = [ round(elem, 2) for elem in initial_c1 ]\n",
    "\n",
    "print \"Centroid c1 is {0}\".format(c1)\n",
    "cluster1=[]\n",
    "\n",
    "initial_c2 = list1[50]\n",
    "c2 = [ round(elem, 2) for elem in initial_c2 ]\n",
    "\n",
    "print \"Centroid c2 is {0}\".format(c2)\n",
    "cluster2=[]\n",
    "\n",
    "initial_c3 = list1[100]\n",
    "c3 = [ round(elem, 2) for elem in initial_c3 ]\n",
    "\n",
    "print \"Centroid c3 is {0}\".format(c3)\n",
    "cluster3=[]\n",
    "\n",
    "Centroids = c1,c2,c3\n",
    "\n",
    "print \"Initial Centroids are {0}\".format(Centroids)\n",
    "sq_distance=0\n",
    "dist=[]\n",
    "diffs=[]\n",
    "cluster=[]\n",
    "count = 0\n",
    "\n",
    "#Take in all data points, calculate distance from each centroid, pick min and assign to cluster bucket\n",
    "while (True):\n",
    "    count = count+1\n",
    "    print \"Pass No.{}\".format(count)\n",
    "    for x in list1:\n",
    "        for c in Centroids:\n",
    "            diffs = []\n",
    "            for num,cent in zip(x,c):\n",
    "                diffs.append(abs(num - cent)**2)\n",
    "            sq_distance = (diffs[-1] + diffs[-2] + diffs[-3] + diffs[-4])\n",
    "            sq_distance = math.sqrt(sq_distance)\n",
    "            dist.append(sq_distance)\n",
    "        #square_distance += abs(num-cent)**2\n",
    "    #min_cluster_distance = min(dist[-1],dist[-2],dist[-3])\n",
    "        if (min(dist[-1],dist[-2],dist[-3]) == dist[-1]):\n",
    "            cluster.append('3.0')\n",
    "            cluster3.append(x)\n",
    "        elif (min(dist[-1],dist[-2],dist[-3]) == dist[-2]):\n",
    "            cluster.append('2.0')\n",
    "            cluster2.append(x)\n",
    "        else:\n",
    "            cluster.append('1.0')\n",
    "            cluster1.append(x)\n",
    "\n",
    "# Recalculate centroid and repeat till iterations doesnt result a change in the point allocations\n",
    "    initial_c4 = np.mean(cluster1, axis=0)\n",
    "    initial_c5 = np.mean(cluster2, axis=0)\n",
    "    initial_c6 = np.mean(cluster3, axis=0)\n",
    "    c4= [ round(elem, 2) for elem in initial_c4 ]\n",
    "    c5= [ round(elem, 2) for elem in initial_c5 ]\n",
    "    c6= [ round(elem, 2) for elem in initial_c6 ]\n",
    "\n",
    "    New_Centroids = c4,c5,c6\n",
    "    print New_Centroids\n",
    "    \n",
    "    #print (lab)\n",
    "    \n",
    "    if (count == 1):\n",
    "        set_x = set([i[0] for i in Centroids])\n",
    "        #print set_x\n",
    "        set_y = set([i[0] for i in New_Centroids])\n",
    "        #print set_y\n",
    "        matches = list(set_x & set_y)\n",
    "        #print matches\n",
    "        lab1 = pd.DataFrame(cluster)\n",
    "        lab1.columns = ['Class_Lab']\n",
    "        intermediate_df1=pd.DataFrame()\n",
    "        intermediate_df1 = pd.concat([train_features, lab1],axis=1)\n",
    "        check_first_df=pd.DataFrame()\n",
    "        check_first_df['new'] = intermediate_df1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "        \n",
    "        if (len(matches) == 3):\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            Centroids = New_Centroids\n",
    "            cluster1=[]\n",
    "            cluster2=[]\n",
    "            cluster3=[]\n",
    "            cluster=[]\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    if (count > 1) :\n",
    "        lab = pd.DataFrame(cluster)\n",
    "        lab.columns = ['Class_Lab']\n",
    "        intermediate_df=pd.DataFrame()\n",
    "        intermediate_df = pd.concat([train_features, lab],axis=1)\n",
    "        check_second_df=pd.DataFrame()\n",
    "        check_second_df['new'] = intermediate_df.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "        check_new_df=pd.DataFrame()\n",
    "        check_new_df['Match']=check_first_df['new'].isin(check_second_df['new'])\n",
    "        check_count_True= len(check_new_df[(check_new_df['Match'] == True)])\n",
    "        if (check_count_True == 90):\n",
    "            break\n",
    "        set_x = set([i[0] for i in Centroids])\n",
    "        #print set_x\n",
    "        set_y = set([i[0] for i in New_Centroids])\n",
    "        #print set_y\n",
    "        matches = list(set_x & set_y)\n",
    "        if (len(matches) == 3):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    \n",
    "      \n",
    "        else:\n",
    "            Centroids = New_Centroids\n",
    "            cluster1=[]\n",
    "            cluster2=[]\n",
    "            cluster3=[]\n",
    "            cluster=[]\n",
    "            \n",
    "            del check_first_df\n",
    "            check_first_df=pd.DataFrame()\n",
    "            check_first_df = check_second_df\n",
    "            del check_second_df\n",
    "            del intermediate_df\n",
    "            del lab\n",
    "        \n",
    "\n",
    "print \"Total no. of passes made are {0}\".format(count)\n",
    "print \"Out of while loop, final Centroids are: {0}\".format(New_Centroids)\n",
    "#print \"Finally, Cluster1 contains these points - {0}\".format(cluster1)\n",
    "#print \"Finally, Cluster2 contains these points - {0}\".format(cluster2)\n",
    "#print \"Finally, Cluster3 contains these points - {0}\".format(cluster3)\n",
    "\n",
    "#Adding labels to each of the points in the final cluster\n",
    "\n",
    "lab = pd.DataFrame(cluster)\n",
    "lab.columns = ['Class_Lab']\n",
    "#print (lab)\n",
    "\n",
    "end_df = pd.concat([train_features, lab],axis=1)\n",
    "\n",
    "#print \"Final Dataframe\"\n",
    "#print end_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1 length is 50\n",
      "Cluster2 length is 52\n",
      "Cluster3 length is 48\n"
     ]
    }
   ],
   "source": [
    "print \"Cluster1 length is {}\".format(len(cluster1))\n",
    "print \"Cluster2 length is {}\".format(len(cluster2))\n",
    "print \"Cluster3 length is {}\".format(len(cluster3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking for accuracy\n",
    "\n",
    "#print \"I am before matching statement\"\n",
    "\n",
    "first_df=pd.DataFrame()\n",
    "second_df=pd.DataFrame()\n",
    "first_df['new'] = training.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df['new'] = end_df.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df=pd.DataFrame()\n",
    "new_df['Match']=first_df['new'].isin(second_df['new'])\n",
    "#print new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is true count 144\n",
      "Classification Accuracy is 0.96\n"
     ]
    }
   ],
   "source": [
    "#print \"I am after matching statement\"\n",
    "\n",
    "count_True= len(new_df[(new_df['Match'] == True)])\n",
    "print \"This is true count {0}\".format(count_True)\n",
    "\n",
    "accuracy=count_True/float(len(list1))\n",
    "print \"Classification Accuracy is {0}\".format(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Class 1 is 1.0\n"
     ]
    }
   ],
   "source": [
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 1.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '1.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "#print len(second_df_1)\n",
    "precision_1 = count_correct_1 / float(len(second_df_1))\n",
    "print \"Precision for Class 1 is {0}\".format(precision_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Class 2 is 0.923076923077\n"
     ]
    }
   ],
   "source": [
    "del new_df1\n",
    "del first_df_1\n",
    "del second_df_1\n",
    "del first_df_2\n",
    "del second_df_2\n",
    "\n",
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 2.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '2.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "len_2 = float(len(second_df_1))\n",
    "precision_2 = count_correct_1 / len_2\n",
    "print \"Precision for Class 2 is {0}\".format(precision_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Class 3 is 0.958333333333\n"
     ]
    }
   ],
   "source": [
    "del new_df1\n",
    "del first_df_1\n",
    "del second_df_1\n",
    "del first_df_2\n",
    "del second_df_2\n",
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 3.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '3.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "len_2 = float(len(second_df_1))\n",
    "precision_3 = count_correct_1 / len_2\n",
    "print \"Precision for Class 3 is {0}\".format(precision_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Class 1 is 1.0\n"
     ]
    }
   ],
   "source": [
    "del new_df1\n",
    "del first_df_1\n",
    "del second_df_1\n",
    "del first_df_2\n",
    "del second_df_2\n",
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 1.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '1.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "len_1 = float(len(first_df_1))\n",
    "recall_1 = count_correct_1 / len_1\n",
    "print \"Recall for Class 1 is {0}\".format(recall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Class 2 is 0.96\n"
     ]
    }
   ],
   "source": [
    "del new_df1\n",
    "del first_df_1\n",
    "del second_df_1\n",
    "del first_df_2\n",
    "del second_df_2\n",
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 2.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '2.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "len_1 = float(len(first_df_1))\n",
    "recall_1 = count_correct_1 / len_1\n",
    "print \"Recall for Class 2 is {0}\".format(recall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Class 3 is 0.92\n"
     ]
    }
   ],
   "source": [
    "del new_df1\n",
    "del first_df_1\n",
    "del second_df_1\n",
    "del first_df_2\n",
    "del second_df_2\n",
    "new_df1=pd.DataFrame()\n",
    "first_df_1=pd.DataFrame()\n",
    "second_df_1=pd.DataFrame()\n",
    "first_df_2=pd.DataFrame()\n",
    "second_df_2=pd.DataFrame()\n",
    "first_df_1 = training[training['Class_Lab'] == 3.0]\n",
    "second_df_1 = end_df[end_df['Class_Lab'] == '3.0']\n",
    "first_df_2['new'] = first_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "second_df_2['new'] = second_df_1.apply(lambda row: ','.join(map(str, row)), axis=1)\n",
    "new_df1['Match']=first_df_2['new'].isin(second_df_2['new'])\n",
    "count_correct_1 = len(new_df1[(new_df1['Match'] == True)])\n",
    "#print count_correct_1\n",
    "len_1 = float(len(first_df_1))\n",
    "recall_1 = count_correct_1 / len_1\n",
    "print \"Recall for Class 3 is {0}\".format(recall_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
